logger:
  classname: salina.logger.TFLogger
  log_dir: brax
  modulo: 10
  every_n_seconds: 10
  verbose: True

env_name: halfcheetah
env:
    classname: brax.envs.create_gym_env
    env_name: ${env_name}

q_agent:
  classname: salina_examples.rl.sac.agents.QMLPAgent
  hidden_size: 256
  n_layers: 2
  env: ${env}

action_agent:
  classname: salina_examples.rl.sac.agents.ActionMLPAgent
  hidden_size: 256
  n_layers: 2
  env: ${env}

algorithm:
  brax_env:
    env_name: ${env_name}

  env_seed: 432

  max_epoch: 10000000

  optimizer:
    classname: torch.optim.Adam
    lr: 0.0001

  use_observation_normalizer: False
  alpha: 1.0
  learning_alpha: True
  policy_delay: 1
  clip_grad: 40
  inner_epochs: 32
  batch_size: 512
  discount_factor: 0.97
  update_target_tau: 0.005
  device: cpu

  n_envs: 256
  n_timesteps: 2
  overlapping_timesteps: 1
  buffer_time_size: 2
  buffer_size: 1048576
  initial_buffer_size: 8192
  reward_scaling: 5.0

  validation:
    evaluate_every: 100
    n_envs: 16
    env_seed: 32

hydra:
  launcher:
    mem_gb: 16
    max_num_timeout: 0
    cpus_per_task: 1
    signal_delay_s: 30
    timeout_min: 120
    gpus_per_node: 1
    tasks_per_node: 1
    partition: learnlab
  job_logging:
    root:
      handlers: []

defaults:
  - override hydra/launcher: submitit_slurm
